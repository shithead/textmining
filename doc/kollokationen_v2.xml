<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE course SYSTEM "elearningtextmining.dtd">
<?xml-stylesheet type="text/xsl" href="elearningtextmining.xsl" ?>
<course>
		<meta>
		<title>e-Learning-Kurs Text Mining</title>
		<version>1.0</version>
		<date>2014-05-01</date>
		<authors>
			<author>Yvonne Krämer</author>
			<author>N. N.</author>
		</authors>
	</meta>
<module id="1">
		<meta>
			<title>Kollokationen</title>
			<version>2.0</version>
			<date>2014-05-01</date>
			<authors>
				<author>Yvonne Krämer</author>
			</authors>
		</meta>
    <chapter id="0" type="learningObjective">
			<page>
			<h1>Lernziele des Moduls "Kollokationen"</h1>
				<p>Nach Bearbeitung des Moduls</p>
				<ul>
					<li>können Sie unterschiedliche Definitionsansätze von Kollokationen wiedergeben.</li>
					<li>sind Sie sich der terminologischen Problematik des Begriffs bewusst.</li>
					<li>haben Sie ein Grundverständnis für statistische Berechnungen und Begrifflichkeiten, insbesondere für Signifikanzmaße, erworben.</li>
					<li>sind Sie in der Lage, Ihrer Fragestellung bzw. Hypothese entsprechend aus verschiedenen Parametern zu wählen.</li>
					<li>haben Sie das Handwerkszeug und die Übung zur Interpretation von Kollokationsprofilen.</li>
				</ul>
				</page>
    </chapter>
		<chapter id="1">	
		<page>
					<h1>Einführung</h1>
			<h2>Was ist eine Kollokation?</h2>
					<p>Der Begriff <term>Kollokation</term> geht auf <person name="Firth, John Rupert">J. R. Firth</person> (<bib id="Firth1957">1957</bib>) zurück, 
					der damit charakteristische und <emph>häufig wiederkehrende Wortkombinationen</emph> bezeichnete. Er war der Ansicht, dass man anhand der Kollokatoren eines Wortes, 
					dessen Bedeutung und Verwendungsweise veranschaulichen kann. </p>
<p type="details">Ein Kollokator ist ein Element, also ein einzelnes Wort einer Wortverbindung bzw. Kollokation.</p>
<p>Vielzitiert ist in diesem Zusammenhang der Satz <person name="Firth, John Rupert">Firths</person> <emph>"You shall know a word by the company it keeps"</emph> (<bib id="Firth1957">
<person name="Firth, John Rupert">Firth</person> 1957</bib>, in <bib id="Evert2009:1213"><person name="Evert, Stefan">Evert</person> 2009: 1213</bib>).</p>
<p type="details">Dieser Ausspruch erinnert an Wittgenstein und seine Gebrauchstheorie der Bedeutung. (vgl. <bib id="Lemnitzer/Zinsmeister 2010:30"> 
<person name="Lemnitzer, Lothar">Lemnitzer</person>/<person name="Zinsmeister, Heike">Zinsmeister</person> 2010:30</bib>)</p>
<p type="example">Beispiele für Kollokationen nach <person name="Firth, John Rupert">Firth</person> wären "Kuh" und "Milch" oder "Tag" und "Nacht".</p>
<p>Im Vordergrund steht für ihn bei Kollokationen die <emph>gegenseitige Erwartbarkeit</emph> (<foreign>mutual expectancy</foreign>) der Wörter und somit auch der Einfluss der <emph>Statistik</emph>.</p>
<p>Die Definition <person name="Firth, John Rupert">Firths</person> bleibt ein recht vager Ausgangspunkt. Heutzutage werden Kollokationen in der Computerlinguistik, der Phraseologie, der Fremdsprachendidaktik 
und nicht zuletzt der Korpuslinguistik daher verschieden ausgelegt.</p>
</page>
<page>
<h2>Lesarten des Begriffs <term>Kollokation</term></h2>
<h3>In der Phraseologie</h3>
<p>versteht man unter einer Kollokation, basierend auf <person name="Hausmann, Franz Josef">Hausmann</person> (<bib id="Hausmann1989">1989</bib>), eine <emph>binäre Struktur</emph>, bestehend aus den zwei Einheiten 
<emph>Basis und Kollokator</emph>.
Es handelt sich um eine <emph>phraseologische Kombination zweier Wörter </emph>zwischen denen ein <emph>hierarchisches Determiniertheitsverhältnis</emph> besteht. 
Anschaulicher wird insbesondere der letzte Punkt durch <person name="Hausmann, Franz Josef">Hausmanns</person> folgende Erklärung: "Der Tisch braucht das Decken nicht, um Tisch zu sein. 
Der Kollokator <kursiv>decken</kursiv> aber braucht dringend <kursiv>Basen</kursiv>, um überhaupt etwas zu sein: 
<kursiv>Dach decken,</kursiv> <kursiv>Stute decken,</kursiv> <kursiv>Unkosten decken</kursiv>  [...]" (<bib id="Hausmann2004: 312"><person name="Hausmann, Franz Josef">Hausmann</person> 2004: 312</bib>).</p>
<p type="example">Weitere Beispiele für Kollokationen nach <person name="Hausmann, Franz Josef">Hausmann</person> sind "Anker lichten" oder "himmelweiter Unterschied".</p>
<p type="details">Zusammengefasst sind Kollokationen bei <person name="Hausmann, Franz Josef">Hausmann</person> demnach zweiteilige Wortverbindungen, 
zwischen denen ein Abhängigkeitsverhältnis und eine Rangordnung bestehen.</p>
<p type="details">Kollokationen werden auch in <person name="Burger, Harald">Harald Burgers</person> Dreibein-Modell der Phraseologie aufgegriffen, in welchem Phraseologismen in die drei Typen 
"Kollokationen", "Idiome" und "Teilidiome" unterteilt sind. Es gilt zu beachten, dass Redewendungen bzw. Idiome von Kollokationen unterschieden werden, da die jeweilige Struktur verschieden ist. 
(<bib id="Hausmann2004:313f."><person name="Hausmann, Franz Josef">vgl. Hausmann </person>2004: 313f.</bib>)
</p>
<p>Auch in der Lexikographie und Fremdsprachendidaktik orientiert man sich am Kollokationsbegriff <person name="Hausmann, Franz Josef">Hausmanns</person>.</p>
<p type="details">Seiner Meinung nach herrscht derzeit ein Terminologiekrieg um die Besetzung des Begriffs <term>Kollokation,</term> wobei das Nebeneinander der verschiedenen Definitionen 
"[...] eine historisch gewachsene Perversion des wissenschaftlichen Diskurses darstellt [...]" (<bib id="Hausmann2004: 312"><person name="Hausmann, Franz Josef">Hausmann</person> 2004: 312</bib>).</p>
</page>
<page>
<h3>In der Computerlinguistik</h3>
<p>sind Kollokationen <emph>lexikalisierte</emph>, also festgelegte <emph>Wortverbindungen mit semantischen oder syntaktischen Besonderheiten</emph>. 
Sie sind <emph>nicht kompositionell</emph> und ihre Elemente sind <emph>nicht modifizierbar </emph>und <emph>nicht substituierbar</emph>. </p>
<p type="details"><emph>Nicht kompositionell</emph> bedeutet, dass sich die Bedeutung der Kollokation nicht aus ihren einzelnen Elementen ableiten lässt.
<emph>Nicht modifizierbar</emph> meint, dass ein Kollokator nicht abgewandelt werden kann, indem beispielsweise statt der Singularform ("Mittel zum Zweck") die Pluralform verwendet wird ("Mittel zu Zwecken").
<emph>Nicht substituierbar</emph> heißt, dass ein Element ("zur Sache kommen") nicht durch ein anderes, wenn auch bedeutungsgleiches Element ausgetauscht werden kann ("zur Sache gelangen").
</p>
<p>Gemäß dieser Definition, können Kollokationen somit beispielsweise im Bereich der maschinellen Übersetzung nicht Wort für Wort in die Zielsprache übertragen werden 
und stellen für die maschinelle Sprachverarbeitung im Allgemeinen eine Herausforderung dar.</p>
<p>Neuerdings wird der Terminus <term>Kollokation</term> in der Computerlinguistik jedoch durch den weniger vorbelasteten Begriff <term><foreign>multiword expression</foreign></term> abgelöst.</p>
<p type="example">Computerlinguistische Kollokationen sind beispielsweise "Mittel zum Zweck" oder "zur Sache kommen".</p>
</page>
<page>
<h3>In der Korpuslinguistik</h3>
<p>werden Kollokationen zumeist in der Tradition <person name="Firth, John Rupert">Firths</person> als <emph>überzufällig häufig gemeinsames Vorkommen zweier Wörter</emph> ausgelegt. </p>
<p type="details">Kann man also mit statistischen Methoden nachweisen, dass "[...] Paare von Wörtern signifikant häufiger miteinander vorkommen, 
als dies auf Grund einer zufälligen Verteilung von Wörtern in Texten zu erwarten wäre [...]" (<bib id="Lemnitzer/Zinsmeister 2010:15f."> <person name="Lemnitzer, Lothar">Lemnitzer</person>/
<person name="Zinsmeister, Heike">Zinsmeister</person>2010:15f.</bib>), so bezeichnet man diese, unabhängig von deren Wohlgeformtheit, als Kollokationen.</p>
<p>Um sie von der phraseologischen Definition klar abzugrenzen, erweitern einige Wissenschaftler wie <person name="Evert, Stefan">Evert</person> (<bib id="Evert2009">2009</bib>) oder 
<person name="Biemann, Chris">Biemann</person>/<person name="Bordag, Stefan">Bordag</person>/<person name="Quasthoff, Uwe">Quasthoff</person> (<bib id="Biemann/Bordag/Quasthoff 2003">2003</bib>) 
die Begriffsbezeichnung und unterscheiden zwischen <emph>empirischen</emph> und theoretischen bzw. <emph>statistischen</emph> und linguistischen <emph>Kollokationen</emph>.</p>
<p type="example">Beispiele für solche empirischen oder statistischen Kollokationen wären demnach Wortpaare wie "und er" oder "welchen Einfluss".</p>
<p>Einen anderen Weg aus dem definitorischen Dilemma geht man beispielsweise am Institut für Deutsche Sprache. 
Dort werden lediglich wohlgeformte Kookkurrenzen, die der Basis-Kollokator-Dichotomie gemäß <person name="Hausmann, Franz Josef">Hausmann</person> entsprechen, als Kollokationen bezeichnet.</p>
</page>
<page>
<h2>Was ist denn eine Kookkurrenz?</h2>
<p>Für <person name="Scherer, Carmen">Scherer</person> beispielsweise sind Kookkurrenzen <emph>überdurchschnittlich häufig benachbarte Wörter</emph> und ein Synonym zu Kollokationen. </p>
<p><person name="Perkuhn, Rainer">Perkuhn</person>/<person name="Keibel, Holger">Keibel</person>/<person name="Kupietz, Marc">Kupietz </person> (<bib id="Perkuhn/Keibel/Kupietz2012">2012</bib>)
 bevorzugen den Begriff <term>Kookkurrenz</term> aufgrund der Problematik der unterschiedlichen Auffassungen des Kollokationsbegriffs nach <person name="Firth, John Rupert">Firth</person> und 
 <person name="Hausmann, Franz Josef">Hausmann</person>. Dabei betonen sie jedoch, dass es nicht um das <emph>bloße Kovorkommen</emph> zweier Wörter geht, wie die wörtliche Bedeutung des Terminus nahelegt, 
sondern dass die Rekurrenz und die statistische Bewertung wesentliche Aspekte der Verbindung darstellen. </p>
<p>Am IDS wiederum sagt man: "Wir definieren 'Kookkurrenz' als eine Kohäsionsqualität, die durch mathematisch-statistische Berechnungen ermittelt wird [...]" (<bib id="Steyer2004: 96">
<person name="Steyer, Kathrin">Steyer</person> 2004: 96</bib>). Lassen sich die statistisch auffälligen Wortverbindungen darüber hinaus in eine hierarchische Beziehung setzen und 
im Sinne <person name="Hausmann, Franz Josef">Hausmanns </person>interpretieren, qualifizieren sie sich außerdem als Kollokationen.</p>
<p type="details">Die kontextuelle Verbindung von "Wasser" und "Verbrauch" wäre gemäß der am IDS vertretenen Auffassung also eine Kookkurrenz, 
da mittels mathematisch-statistischer Berechnungen ein starker und auffälliger Zusammenhalt der Wörter nachgewiesen werden konnte. Das Wortpaar "sauber" und "Wasser" entspricht zusätzlich noch 
der Definition von <person name="Hausmann, Franz Josef">Hausmann</person> und stellt somit eine Kollokation dar.	</p>
</page>
<page>
<h2>Und dann wäre da auch noch die Kolligation...</h2>
<p>Der Begriff <term>Kolligation</term> findet sich nicht allzu oft in korpuslinguistischer Sekundärliteratur, wird dann aber zumindest einheitlich gebraucht. 
Im Gegensatz zur lexikalischen oder inhaltlichen Ebene der Kollokation, steht bei der Kolligation die <emph>innere Struktur</emph>, also die <emph>grammatikalische Ebene</emph> im Vordergrund. 
Das Augenmerk liegt dabei auf der <emph>grammatischen Beziehung zwischen Wortpaaren</emph>, wie sie etwa zwischen Verben und Adverbien besteht. </p>
<p type="details">Diese, ein Syntagma bildenden Einheiten, erinnern an Kollokationen nach <person name="Hausmann, Franz Josef">Hausmann</person>. 
<person name="Lemnitzer, Lothar">Lemnitzer</person>/<person name="Zinsmeister, Heike">Zinsmeister</person> führen als Beispiel für eine Kolligation "Antrag stellen" an und bezeichnen im Gegensatz dazu 
die frequente Wortverbindung "und er" als Kollokation. </p>
<p type="example">Ein Beispiel für eine Kolligation ist "Antrag stellen".</p>
</page>
<page>
<p>Referenzliteratur:</p>
<ul>
<li>vgl. Biemann/Bordag/Quasthoff 2003</li>
<li>vgl. Evert 2009: 1212-1214</li>
<li>vgl. Hausmann 2004: 312-320</li>
<li>vgl. Lemnitzer/Zinsmeister 2010: 15f., 30f.</li>
<li>vgl. Perkuhn/Keibel/Kupietz 2012: 112f.</li>
<li>vgl. Scherer 2006: 46</li>
<li>vgl. Steiner 2004: 38f.</li>
<li>vgl. Steyer 2004: 96-99</li>
</ul> 
<p>Davon lohnenswerte/lesenswerte Vertiefungsliteratur:</p>
<ul>
<li>vgl. Evert 2009: 1212-1214</li>
<li>Perkuhn/Keibel/Kupietz 2012: 112f.</li>
<li>Steyer 2004: 96-99</li>
</ul>
</page>
<page>
<img src="">Animation/Bild oder ähnliches</img>
</page>
  </chapter>
<chapter id="2">
<page>
<h1>Terminlogische Festlegung</h1>
<p>Durch die vorhergehenden Ausführungen sollte klar geworden sein, dass es sowohl in Bezug auf den Begriff <term>Kollokation</term>, wie auch auf den Begriff <term>Kookkurrenz</term> eine gewisse Problematik gibt, 
während von <term>Kolligationen</term> eher selten die Rede ist.</p>
<p>Im Fokus der Korpuslinguistik steht das <emph>Kovorkommen von Wörtern</emph>. Von Interesse ist dabei aber nicht die bloße Kookkurrenz, sondern die Frage, ob eine Art Anziehungskraft zwischen den Wörtern besteht 
und deren gemeinsames Auftreten <emph>überzufällig häufig</emph>, wenn nicht gar <emph>signifikant</emph> ist. Dabei gilt es zu beachten, dass die Wörter nicht unmittelbar nebeneinander stehen müssen. 
Üblicherweise werden <emph>Textfenster</emph> von fünf Wörtern rechts und links vom Bezugswort als Analysegrundlage herangezogen. </p>
<p type="details">Darüber hinaus gibt es aber auch Ansätze, die das signifikant gemeinsame Vorkommen zweier Wörter in einem Textausschnitt (z.B. innerhalb eines Satzteils oder Satzes) untersuchen, 
was sich vor allem bei Sprachen mit vergleichsweise freier Wortstellung anbietet. Bei einer anderen Herangehensweise, werden nur die Wörter als Kookkurrenzen  aufgefasst, 
die in direkter oder zum Teil auch indirekter syntaktischer Beziehung stehen. Es werden also nur Kolligationen analysiert. (<bib id="Evert2009:1222f."><person name="Evert, Stefan">vgl. Evert </person>2009: 1222f.</bib> )</p>
<p>Dieser statistische Mehrwert gegenüber einer Kookkurrenz soll in der Tradition <person name="Firth, John Rupert">Firths </person>nachfolgend als <emph>Kollokation</emph> bezeichnet werden. 
Zwar besteht somit eine Ambiguität zur Begrifflichkeit <person name="Hausmann, Franz Josef">Hausmanns</person>, doch die Aspekte der Wohlgeformtheit und der hierarchischen Determiniertheit bleiben unberücksichtigt. </p>
<p type="details">Zusammenfassend heißt das: Wenn zwei Begriffe mittels mathematisch-statistischer Verfahren als auffällig dargestellt werden, handelt es sich um eine Kollokation, 
egal ob die beiden Wörter eine grammatikalisch korrekte oder inhaltlich sinnvolle Einheit bilden oder nicht.</p>
</page>
</chapter>
<chapter id="3">
<page>
<h1>Wissenswerte Begriffe</h1>
<h2>Kollokationsanalyse</h2>
<p>Bei einer Kollokationsanalyse - in der Sekundärliteratur auch Kookkurrenzanalyse genannt - werden <emph>mithilfe statistischer Verfahren</emph> die <emph>auffälligsten Kollokatoren</emph> oder auch Kookkurrenzpartner 
eines <emph>gewählten Bezugswortes</emph> ermittelt. Hierfür müssen einige <emph>Parameter</emph> sowie ein <emph>Signifikanzmaß</emph> festgelegt werden. </p>
<p type="details">Diese bilden die Grundlage der Berechnungen und können unterschiedliche Betrachtungsweisen des Korpus wiederspiegeln. Sie sollten daher an die Frage- bzw. Zielstellung angepasst werden.</p>
<p>Als Ergebnis einer Kollokationsanalyse wird das Kollokationsprofil eines Bezugswortes angezeigt.</p>
<img>"Beispielhaftes Ergebnis einer Kollokationsanalyse"</img>
</page>
<page>
<h2>Kollokationsprofil</h2>
<p>Das Kollokationsprofil eines Wortes ist die <emph>Gesamtheit seiner relevanten Kollokationen</emph>. Während eine einzelne Kollokation einen Teilbereich davon abbildet, wie ein Wort üblicherweise gebraucht wird, 
stellt ein Kollokationsprofil "[...] viele, wenn nicht sogar alle wichtigen Aspekte oder Nuancen der Verwendung eines Wortes [dar]. Wir können uns damit einen Überblick über alle wichtigen Diskurse verschaffen, 
in denen sich die vielleicht unterschiedlichen Bedeutungen eines Wortes konstituiert haben" 
(<bib id="Perkuhn/Keibel/Kupietz2012:127"><person name="Perkuhn, Rainer">Perkuhn</person>/<person name="Keibel, Holger">Keibel</person>/<person name="Kupietz, Marc">Kupietz</person>
Perkuhn/Keibel/Kupietz 2012: 127</bib>). </p>
</page>
<page>
<h2>Kollokationen erster/zweiter/dritter Ordnung</h2>
<p>Grundsätzlich liegt Kollokationen eine binäre Struktur zugrunde: Berechnet man auf Grundlage eines Bezugswortes die signifikantesten Kollokationen, 
so wird als Resultat üblicherweise eine Liste mit den signifikantesten Kollokatoren erster Ordnung ausgegeben. Ansätze wie bspw. das Clustering erweitern diese Struktur, 
indem in einem zweiten Schritt die signifikantesten Kollokatoren eines Kollokators erster Ordnung berechnet werden. Auf diese Weise erhält man die Kollokatoren zweiter Ordnung. 
Man kann dieses Vorgehen auch auf Kollokatoren dritter Ordnung und darüber hinaus anwenden. Die erzielten Ergebnisse bilden dann sozusagen ein Kollokationsnetz und können auch entsprechend visualisiert werden:</p>
<img>Kollokationsnetz/Cluster/Graph</img>
</page>
</chapter>
<chapter id="4">
<page>
<img>Wozu?</img>
</page>
</chapter>
<chapter id="4">
<page>
<h1>Anwendungsmöglichkeiten</h1>
<h2>Wozu kann die Berechnung von Kollokationen dienen?</h2>
<ul>
<li>Als Hinweis für die Anordnung bzw. Hierarchie von Lesarten eines sprachlichen Zeichens in einem Wörterbuchartikel.</li>
<li type="details">	Welches ist die gängigste Bedeutung des Lexems?</li>
<li>Zur Identifikation, Verifizierung und Beschreibung typischer Wortverbindungen und Wortverbindungphänomene (z.B. Idiome) </li>
<li type="details">	Welche Kollokationen werden verwendet?</li>
<li type="details">	Welche sind besonders gebräuchliche Kollokationen und welche finden sich kaum oder gar nicht?</li>
<li type="details">	In welcher Bedeutung und in welchem Kontext werden sie gebraucht?</li>
<li>Gängige grammatische Gebrauchsmuster können ermittelt werden</li>
<li>Syntaktische Bindungen können ausfindig gemacht werden</li>
<li type="details">z.B. typische präpositionale Anschlüsse</li>
<li>Die Bedeutungsfelder eines Wortes werden anschaulich</li>
<li>Thematische Felder können ausgemacht werden</li>
<li>Die Verwendungsweisen von bestimmten Begriffen im Diskurs können deutlich gemacht werden </li>
<li>Kollokationen können als Widerspiegelung von Traditionen des Formulierens bzw. Gebrauchskonventionen untersucht werden</li>
</ul>
<p>Kollokationsanalysen sind damit auch für die Lexikographie und Lexikologie, die Fremdsprachendidaktik und die Übersetzungswissenschaft von besonderer Bedeutung.</p>
</page>
<page>
<p>Referenzliteratur:</p>
<ul>
<li>vgl. Lemnitzer/Zinsmeister 2010: 144f.</li>
<li>Steyer 2004: 87-94, 103</li>
</ul>
</page>
<page>
<h2>Praxisbezug</h2>
<h3>Anwendungsbeispiel aus der Lexikographie und Fremdsprachendidaktik</h3>
<p>Vor dem Hintergrund, dass usuelle Wortverbindungen einen essentiellen Bestandteil unserer Sprache darstellen, für Nichtmuttersprachler aber oft eine große Hürde sind, 
entstand am IDS 2008 das Projekt "SprichWort. Eine Internetplattform für das Sprachenlernen". 2011 ging es in das Projekt "Usuelle Wortverbindungen" über 
und seine Zielgruppe bilden insbesondere Fremdsprachenlerner und –lehrer sowie Entwickler von Lehr- und Lernmaterialien.</p>
<p type="quote">"Wortverbindungen verkörpern [...] 'geronnene kulturelle Erfahrungen‘ einer Sprachgemeinschaft (z.B. Sprichwörter), und es ist deshalb wichtig, sie zu sammeln, zu archivieren 
und in ihrem gegenwärtigen Gebrauch auch für die Nachwelt zu dokumentieren. Wenn wir die 'Logik der Wortverbindungen‘ verstehen, können wir sehr viel über die Strukturen der Sprache und des Denkens erfahren. 
Deshalb kann die Erforschung von Wortverbindungen auch zur Theorienbildung in der Linguistik selbst wertvolle Beiträge leisten" (<bib id="N.N">IDS/Steyer"</bib>).</p>
<p>Für gewöhnlich greifen Lexikographen bei dem Versuch, übliche Wortverbindungen und Verwendungsbeispiele aufzulisten, auf ihre Erfahrung, Intuition und Sprachkompetenz zurück. 
Zudem werden Versuchspersonen befragt oder psychologische Assoziationstests durchgeführt. </p>
<p>Am Institut für Deutsche Sprache wollte man sich hingegen die Computertechnologie und den Bestand an Korpora zunutze machen. Mit statistischen Methoden wurden authentische Sprachdaten analysiert und linguistisch interpretiert.</p>
<p>Basierend auf dem Deutschen Referenzkorpus entstand so ein erstes, empirisch untermauertes und online dokumentiertes Kerninventar der aktuell gebräuchlichen Sprichwörter des Deutschen. 
Die 300 Wörterbuchartikel beinhalten eine Validierung des Sprichwortstatus, die Bedeutung, in der das Sprichwort verwendet wird, seine typischen Formvarianten und lexikalischen Ersetzungen, 
Beispiele für die textuelle Einbettung des Sprichwortes sowie seine typischen Gebrauchsbesonderheiten. Zudem sind Sprichwort-Äquivalente für andere Sprachen verlinkt. 
Das Sprichwörterbuch ist zum einen über die SprichWort-Plattform verfügbar und wurde zum anderen in das Online-Wortschatz-Informationssystem Deutsch (OWID) des Instituts für Deutsche Sprache integriert.</p>
<p><a href="http://www.owid.de/index.jsp"/></p>
<p><a href="http://www.sprichwort-plattform.org/"/></p>
</page>
<page>
<p>Referenzliteratur</p>
<ul>
<li><a href="http://www1.ids-mannheim.de/lexik/uwv.html"/></li>
<li><a href="http://www1.ids-mannheim.de/lexik/uwv/uwv.html"/></li>
<li><a href="http://www.owid.de/wb/sprw/start.html"/></li>
<li><a href="http://www1.ids-mannheim.de/lexik/sprichwort/projekt.html"/></li>
</ul>
</page>
<page>
<h3>Anwendungsbeispiel aus der Diskurslinguistik</h3>
<p>Angelehnt an die Kognitive Linguistik sowie die Stereotypen- und Diskursforschung unternimmt <person name="Vogel, Friedemann">Friedemann Vogel </person>in einer Studie den Versuch, 
mittels korpuslinguistischer Verfahren das öffentliche Medienimage der "Türkei" sowie von "Türken" im deutschsprachigen Raum zu untersuchen. </p>
<p>"Im Fokus liegen dabei rekurrente Sprachmuster, die Hinweise geben auf medienvermittelte 'Prototypen der‘ bzw. 'des‘ 'Türken' / 'der‘ 'Türkei'"
 (<bib id="Vogel2010"><person name="Vogel, Friedemann">Vogel</person> 2010: 11</bib>). </p>
 <p>Um diesen auf den Grund zu gehen, macht er zunächst sämtliche Lexeme ausfindig, welche die Zeichenfolge "türk" enthalten. In einem nächsten Schritt führt er unter anderem eine Kookkurrenzanalyse des Lexems 
 "Türkei" mit einer Fenstergröße von -5/+5 durch. </p>
 <p>Er stellt dabei fest, dass die hitzige Debatte um den EU-Beitritt der Türkei ein ganz zentrales Thema seiner Korpusdaten darstellt. </p>
 <p>Des Weiteren lassen sich die 100 signifikantesten Kookkurrenzpartner von "Türkei", wie zum Beispiel "Irak", "Nato", "Frauen", "Erdbeben", "Reise" oder "abgeschoben" "[...] den Kontexten [...] 'Integration und Assimilation', 
 'Militärische Bündnispartner und Intervention' [...], 'Menschenrechts- bzw. Demokratiedefizit' [...], 'problematische Geschlechterverhältnisse' [...], 'Religion', [...] 'Terrorismus, Radikalität, Verschlossenheit und orientale Fremde'; 
 ferner 'Naturkatastrophen' [...], 'Urlaub' [...] sowie schließlich 'Asyl- und Abschiebeprozesse' [...] [zuordnen]" (<bib id="Vogel2010:20"><person name="Vogel, Friedemann">Vogel</person>2010: 20</bib>).</p>
 <p>In Verbindung mit weiteren Berechnungen kommt <person name="Vogel, Friedemann">Vogel </person>letztlich zu dem Fazit, dass man in Deutschland lebenden Türken zwar durchaus positive Eigenschaften zuschreibt, 
 diese aber durch negative Attribute überzeichnet werden. Insbesondere junge Türken werden des Öfteren als gefährlich und auf verschiedenen Ebenen als Bedrohung wahrgenommen.</p>
 <p>Die Türkei gilt als in sich widersprüchliches Land, wobei auch positive Aspekte zu finden sind, da es sich um einen wirtschaftlichen und militärischen Partner sowie ein beliebtes Urlaubsziel handelt.</p>
 <p>Vogel räumt schließlich noch zwei wichtige Punkte ein: Zum einen ist es korpuslinguistisch kaum möglich, Ironie in den Daten auszumachen 
 und zum anderen würde eine kontrastive Analyse der Ergebnisse mit einem Referenzkorpus großes Potenzial bergen.</p>
 <p>vgl. Vogel 2010: QUELLE</p>
 <p>Es lässt sich also festhalten, dass Kookkurrenzanalysen ein produktives wie nützliches Verfahren für die Diskurslinguistik darstellen und auch dem Gebiet der Linguistischen Imageanalyse dienlich sein können.</p>
</page>
</chapter>
<chapter id="5">
<page>
<h1>Ein bisschen Statistik</h1>
<img>Auch das noch!</img>
<p>Statistische Berechnungen spielen eine wesentliche Rolle bei Kollokationsanalysen. Um die Analyseparameter einstellen und die Ergebnisse richtig interpretieren zu können, sollte man gewisse Grundkenntnisse in diesem Bereich erwerben.
 In den bisherigen Aussagen über Kollokationen fielen bereits die mathematisch-statistischen Begriffe <term>überzufällig häufig </term>und <term>signifikant</term>. Zunächst soll geklärt werden, was genau man darunter versteht:</p>
 </page>
 <page>
<h2>Überzufällig häufig</h2> 
 <p>Verteilt man die Wörter in einem Korpus ganz beliebig, so können ein Wort a und ein Wort b <emph>x-mal zufällig</emph> gemeinsam vorkommen. Ist eine Wortverbindung zufällig, so sind die beiden Wörter voneinander unabhängig. 
 Man nennt dies auch die <emph>Nullhypothese</emph>. Kommen die beiden Wörter aber <emph>häufiger </emph>gemeinsam vor <emph>als x</emph>, so ist dieses Vorkommen <emph>überzufällig häufig</emph>.</p>
 <p type="details">In natürlichen Sprachen ist auszuschließen, dass Wörter zufällig aufeinandertreffen, da sie  syntaktischen, semantischen und lexikalischen Einschränkungen unterliegen. 
 Daher ist die sogenannte Nullhypothese, bei der man davon ausgeht, dass Wort a und Wort b voneinander unabhängig sind und keinerlei Attraktion zwischen ihnen besteht, umstritten.</p>
 <p>Denken Sie zurück an Ihren Mathematikunterricht:</p> 
 <p>Zu Beginn wird die Wahrscheinlichkeitsrechnung oftmals anhand von Würfeln erklärt. Wir wollen das einfachere Beispiel einer Münze heranziehen: Wirft man eine Münze zehnmal, so könnte man erwarten, 
 dass fünfmal Kopf und fünfmal Zahl erscheint. Zeigt die Münze sechs- oder siebenmal Kopf, so kann das immer noch Zufall sein. Trotzdem <emph>übersteigt </emph>das Ergebnis 
 unsere <emph>Erwartung einer gleichmäßigen Verteilung</emph> und ist damit überzufällig häufig.</p>
</page>
<page>
<h2>Signifikant</h2>
<p>Bleiben wir bei erwähntem Beispiel: Wirft man eine Münze zehnmal und sieht neun- oder gar zehnmal Kopf, so ist es mehr als unwahrscheinlich, dass es sich hierbei noch um Zufall handelt. 
Die <emph>Abweichung</emph> von dem, was wir erwartet hätten, ist <emph>so stark</emph>, dass sie als signifikant bezeichnet werden kann. </p>
<p>Bei der Interpretation von überzufällig häufig auftretenden Kollokationen kann man Aussagen über das zugrundeliegende Korpus ableiten. Sind Wortverbindungen jedoch signifikant, 
so kann man allgemein gültige Schlussfolgerungen ziehen. Da es sich um statistische Berechnungen auf der Grundlage von Wahrscheinlichkeiten handelt, sind diese aber trotz allem fehlbar. </p>
</page>
<page>
<p>Bei der Berechnung von überzufälliger Häufigkeit und Signifikanz geht es also darum zu ermitteln, wie häufig ein Wort bzw. eine Wortverbindung vorkommt und wie oft wir das erwartet hätten. 
Für eine Kollokationsanalyse sind daher folgende Frequenzen relevant:</p>
</page>
<page>
<h2>Beobachtete Frequenz</h2>
<p>Die sogenannte <emph>Observed Frequency</emph> <quantity>(O)</quantity> ist schlicht die <emph>Anzahl der tatsächlichen Vorkommen</emph> einer Wortverbindung im Korpus. </p>
<p>Diese Frequenz sowie das tatsächliche Vorkommen von Bezugswort, Kollokator und der anderen Wörter im Korpus sind erforderlich, um die Signifikanz einer Kollokation berechnen zu können. Man erhält die benötigten Werte, 
indem ausgezählt wird: </p>
<ul>
<li>a) wie oft Wort<subscripted>1</subscripted> und Wort<subcripted>2</subcripted> (in einem vorher definierten Textfenster) gemeinsam vorkommen, </li>
<li>b) wie oft nur Wort<subscripted>1</subscripted> vorkommt, </li>
<li>c) wie oft Wort<subcripted>2</subcripted> alleine vorkommt und </li>
<li>d) wie oft weder Wort<subscripted>1</subscripted> noch Wort<subcripted>2</subcripted> vorkommen, also wie viele Wörter nicht Wort<subscripted>1</subscripted> oder Wort<subcripted>2</subcripted> sind.</li>
</ul>
<p>Es kann hilfreich sein, die beschriebenen Angaben in einer sogenannten Kontingenztabelle zu erfassen. </p>
<p type="details">In der Statistik bedeutet "Kontingenz": "Häufigkeit bzw. Grad der Wahrscheinlichkeit des gemeinsamen Auftretens zweier Sachverhalte, Merkmale usw." (Duden online, Stichwort "Kontingenz")</p>
</page>
<page><p>Für die beobachtete Frequenz <quantity>(O)</quantity>, wäre diese folgendermaßen aufzubauen:</p>
<table>Kontingenztabelle für O</table>
</page>
<page>
<p>Setzt man beispielsweise die Kollokation "heute Abend" mit fiktiven Werten in eine solche Tabelle ein, dann ergibt sich dieses Bild:</p>
<table>Kontingenztabelle für O mit Beispielwerten</table>
</page>
<page>
<p>Gemäß der beispielhaften Tabelle kommt die Kollokation "heute Abend" also 20-mal im Korpus vor. "Heute" in Verbindung mit anderen Wörtern erscheint 500-mal, "Abend" findet sich 200-mal im Umfeld anderer Wörter. 
Zudem lassen sich 2000 Wörter zählen, in deren Kontext man weder auf "heute" noch auf "Abend" trifft.</p>
<p type="details">Es gilt stets zu beachten, dass sich die Werte auf ein vorher definiertes Textfenster beziehen. </p>
<p>Um eine zufällige Verteilung der Wörter ausschließen zu können, spielen neben den tatsächlichen Vorkommen auch die erwarteten Frequenzen eine wichtige Rolle:</p>
</page>
<page>
<h2>Erwartete Frequenz</h2>
<p>Um zu ermitteln, ob die Wörter gleichmäßig bzw. zufällig im Korpus verteilt sind, betrachtet man die sogenannte erwartete Frequenz <quantity>(E)</quantity>.</p>
<p type="details"><quantity>"E</quantity> is important as a reference point for the interpretation of <quantity>O</quantity>, since two frequent words might cooccur quite often purely by chance." 
(<bib id="Evert2009:1228"><person name="Evert, Stefan">Evert</person>2009: 1228</bib></p>
<p>Für die Berechnung der <emph>erwarteten Frequenz einer Wortverbindung</emph>, setzt man die <emph>Einzelfrequenzen der Kollokatoren in Relation zur Gesamtgröße des Korpus</emph>. 
Man zählt also zunächst das Vorkommen (<quantity>f<subscripted>1</subscripted></quantity>) von Wort <kursiv>a</kursiv> sowie das Vorkommen (<quantity>f<subscripted>2</subscripted></quantity>) von Wort <kursiv>b</kursiv>. 
In Bezug zur Gesamtzahl (<quantity>N</quantity>) an Worttoken im Korpus berechnet man die sogenannte <emph>Expected Frequency</emph> (<quantity>E</quantity>) dann wie folgt: </p>
<img>Formel</img>
<p type="details"><person name="Evert, Stefan">Evert</person>führt das Ganze etwas detaillierter an dem Beispiel der Kollokation <kursiv>is to</kursiv> aus, welche 260-mal im Brown Korpus vorkommt. 
Der Kollokator <kursiv>is</kursiv> weist dabei eine Frequenz von etwa 10000 und <kursiv>to</kursiv> von 26000 pro 1 Million Worttoken auf. Bei einer zufälligen Verteilung der Wörter, würde man die Kollokation etwa 260-mal erwarten. 
Da dies dem tatsächlichen Vorkommen entspricht, ist <kursiv>is to</kursiv> nicht als signifikant anzusehen. </p>
<p type="details">Das erwartete Vorkommen einer zufälligen Wortverbindung berechnet sich dabei folgendermaßen: "<kursiv>to</kursiv> occurs 26 times every 1,000 words on average. 
If there is no association between <kursiv>is</kursiv> and <kursiv>to</kursiv>, then each of the 10,000 instances of <kursiv>is</kursiv> in the Brown corpus has a chance of 26/1,000 to be followed by <kursiv>to</kursiv>. 
Therefore, we expect around 10,000 X (26/1,000) = 260 occurrences of the bigram <kursiv>is to</kursiv>, provided that there is indeed no association between the words." (<bib id="Evert2009:1225">
<person name="Evert, Stefan">Evert</person>2009: 1225</bib>)</p>
<p>Im Grunde gilt eine Kollokation dann als signifikant, wenn die beobachtete Frequenz <quantity>(O)</quantity> die erwartete Frequenz <quantity>(E)</quantity> deutlich übersteigt, 
wobei stets auch ein gewisser Toleranzbereich einbezogen wird.</p>
<p>Die meisten Signifikanz- bzw. Assoziationsmaße berücksichtigen dabei jedoch nicht nur <quantity>(O)</quantity> und <quantity>(E)</quantity> der Kollokation, sondern beziehen die beobachtete und erwartete Frequenz 
für jeden der bereits beschriebenen vier Werte in die Berechnung ein. </p>
<p>Es liegt deshalb nahe, in einem zweiten Schritt ebenfalls eine Kontingenztabelle der erwarteten Werte zu erstellen. </p>
</page>
<page>
<p>Angelehnt an die Formel <img>Formel</img> zur Berechnung der erwarteten Frequenz einer Kollokation berechnen sich die anderen Felder wie folgt:</p>
<table>Kontingenztabelle für E</table>
<p type="details">Im Grunde rechnet man für jede Zelle <img>Formel</img>.</p>
</page>
<page>
<p>Verwendet man das gleiche Beispiel wie bei den beobachteten Frequenzen, ergeben sich diese Werte:</p>
<table>Kontingenztabelle für E mit Beispielwerten</table>
</page>
<page>
<p>Aus den Kontingenztabellen der beobachteten und der erwarteten Frequenzen lassen sich schließlich alle Werte entnehmen, die für einen sogenannten Signifikanztest benötigt werden.</p>
</page>
<page>
<h2>Signifikanzmaße </h2>
<p>Wenn Wörter immer wieder gemeinsam vorkommen, liegt es nahe, von einer gewissen Anziehung oder Kohäsion zwischen ihnen auszugehen. Die <emph>Attraktionsstärke bzw. der Kohäsionsgrad zweier Wörter </emph>
kann mithilfe von Signifikanzmaßen ermittelt werden. </p>
<p>Wie der Name bereits andeutet, geben Signifikanzmaße Aufschluss über die<emph> Signifikanz von Kollokationen</emph> und <emph>bewerten diese</emph> somit <emph>statistisch hinsichtlich ihrer Auffälligkeit</emph>. 
Dadurch wird man auch auf Wortverbindungen aufmerksam, die vielleicht nicht sehr häufig, deren Kombination aber auffällig ist. </p>
<p type="details">Von einer bloßen Rekkurrenz eines Wortpaares, also einer hohen Frequenz einer Kollokation, kann man noch nicht auf eine starke Anziehung zwischen zwei Wörtern schließen. 
Mithilfe statistischer Signifikanzmaße kann man hingegen den Kohäsionsgrad messen und so ggf. ausschließen, dass zwei Wörter zufällig immer wieder zusammen vorkommen. Im Grunde wird also die Frage beleuchtet, 
wie unwahrscheinlich es ist, dass die beiden Wörter rein zufällig zusammen vorkommen und keinerlei Attraktion zwischen ihnen besteht.</p>
<p>An dieser Stelle sollen zwei Signifikanzmaße kurz vorgestellt werden.</p>
</page>
<page>
<h3>Chi-Quadrat-Test</h3>
<p>Der Chi-Quadrat-Test, oder auch <quantity>SYMBOL Chi hoch 2</quantity>-Test misst im Grunde die Differenz zwischen den beobachteten und den erwarteten Frequenzen und bezieht dabei 
alle Werte der zuvor erstellten Kontingenztabellen ein. Für jede Zelle wird also <img>Formel</img>ermittelt und die jeweiligen Ergebnisse werden dann addiert.</p>
<p>Daraus ergibt sich die Formel <img>Formel</img></p>
<p>"The essence of the test is to compare the observed frequencies in the table with the frequencies expected for independence. If the difference between observed and expected frequencies is large, 
then we can reject the null hypothesis of independence." (<bib id="Manning/Schütze2003:168"><person name="Manning, Christopher D.">Manning</person>/<person name="Schütze, Hinrich">Schütze</person>
Manning/Schütze 2003: 168</bib>)</p>
<p>Um herauszufinden, ob der so berechnete Wert signifikant ist, muss man eine Tabelle der kritischen Werte für <quantity>SYMBOL Chi hoch 2</quantity> zu Rate ziehen. Diese besagt für eine Vierfeldertafel, 
dass <quantity>SYMBOL Chi hoch 2</quantity> größer als 3,84 sein müsste, damit die Wahrscheinlichkeit für die Nullhypothese bei lediglich 5% liegt (<quantity>p</quantity> = 0,05). Ist <quantity>SYMBOL Chi hoch 2</quantity> 
größer als 6,64, so kann die Nullhypothese mit einer Wahrscheinlichkeit von 99% abgelehnt werden (<quantity>p</quantity> = 0,01) und wenn <quantity>SYMBOL Chi hoch 2</quantity>den Wert von 10,83 überschreitet, 
so ist es zu 99,9% sicher (<quantity>p</quantity> = 0,001), dass die Kollokation signifikant und das gemeinsame Vorkommen nicht zufällig ist.</p>
<p>Problematisch ist der Chi-Quadrat-Test, wenn die Zahlen in der Kontingenztabelle sehr klein sind. Bei Werten unter <quantity>E</quantity> = 5 sind die Ergebnisse nicht mehr zuverlässig.</p>
</page>
<page>
<h3>Log-Likelihood-Test</h3>
<p>Im Gegensatz zu <quantity>SYMBOL Chi hoch 2</quantity> ist der Log-Likelihood-Test auch gegenüber kleinen Werten von <quantity>E</quantity> robust und daher ebenso auf spärliche Datenmengen anwendbar. 
Die Log-Likelihood-Ratio eignet sich am besten für die Berechnung von Kollokationen und ist das gängigste Signifikanzmaß in der Korpuslinguistik. Insofern es zur Wahl steht, sollte man diesem Maß also stets den Vorzug geben. </p>
<p>Die Formel zur Berechnung der LLR lautet wie folgt:</p>
<img>Formel</img>
<p>Will man die Signifikanz des ermittelten Wertes feststellen, so kann man erneut auf die kritischen Werte für <quantity>SYMBOL Chi hoch 2</quantity> zurückgreifen, da beiden Tests das gleiche Prinzip zugrundeliegt .</p>
</page>
<page>
<p>Allgemein sollte man in Bezug auf Signifikanzmaße berücksichtigen, dass einzelne Werte nicht unbedingt aussagekräftig sind. Ergibt sich beispielsweise für die Kollokation "heute abend" eine LLR von 2035.949, 
so ist diese zwar hochsignifikant, die Wortverbindung "heute morgen" weist mit einer LLR von 7298.124 jedoch eine weitaus interessantere Kohäsion auf. </p>
<p>Davon abgesehen haben Signifikanzmaße den Schwachpunkt, dass, sobald <quantity>O</quantity> einen gewissen Wert überschreitet, schon ein vergleichsweise geringer Abstand zwischen <quantity>O</quantity> 
und <quantity>E</quantity> zu einem hohen Signifikanzwert führt. Auch <person name="Manning, Christopher D.">Manning</person>/<person name="Schütze, Hinrich">Schütze</person> stellen deshalb fest: 
"[...] [S]tatistical tests are most useful as a method for ranking collocations. The level of significance itself is less useful. In fact, in most publications that we cite in this chapter, the level of significance is never looked at. 
All that is used is the scores and the resulting ranking." (<bib id="Manning/Schütze2003:166">2003: 166</bib> )</p>
<p>Verwendet man eine Korpusanalysesoftware, so erfolgt die Berechnung des gewählten Signifikanzwertes dankenswerterweise automatisch. Üblicherweise werden die Kollokatoren, entsprechend der ausgesuchten Parameter, 
absteigend nach Signifikanz bzw. Frequenz sortiert aufgelistet. Da hohe Zahlen eine starke Attraktion indizieren, sind die Angaben intuitiv zu interpretieren.</p>
</page>
<page>
<h2>Zipfs Gesetz</h2>
<p>Der Vollständigkeit halber, sollte im Rahmen des Statistik Kapitels auch auf die Zipfschen Gesetze eingegangen werden. Als Ausgangspunkt für sein wohl bekanntestes Gesetz, zählt man, 
wie oft sich einzelne Wortformen in einem Korpus finden und erstellt daraus eine Liste, die absteigend nach Frequenz sortiert wird. Die Frequenz (<quantity>f</quantity>) wird dann zu dem Rangplatz (<quantity>r</quantity>) 
einer Wortform in Beziehung gesetzt: </p>
<img>Formel</img>
<p>Diese Formel drückt aus, dass der Rang (<quantity>r</quantity>) einer Wortform, multipliziert mit deren Häufigkeit (<quantity>f</quantity>) in etwa konstant ist.</p>
<p type="details">Das bedeutet, dass zum Beispiel die Wortform auf Rang 50 dreimal so häufig im Korpus vorkommen sollte, wie die Wortform auf dem 150ten Listenplatz.</p>
<p>Mit anderen Worten: </p>
<img>Formel</img>
<p>Die Frequenz (<quantity>f</quantity>) einer Wortform in einem Korpus ist annähernd umgekehrt proportional zu ihrer Listenposition (<quantity>r</quantity>).</p>
<p>Zipfs Gesetz hat einige Schwachstellen, doch im Grunde ist es eine nützliche Beschreibung der Häufigkeitsverteilung in natürlichen Sprachen. 
Denn es besagt, dass lediglich ein geringer Teil an Wörtern sehr häufig in einer Sprache vorkommt, einige Wörter finden sich im mittleren Frequenzbereich und viele Wörter erscheinen nur vereinzelt. </p>
</page>
<page>
<p>Man kann dies folgendermaßen visualisieren:</p>
<img>Zipfsche Kurve</img>
</page>
<page>
<p>"[...] [T]he main upshot of Zipf’s law is the practical problem that for most words our data about their use will be exceedingly sparse. Only for a few words will we have lots of examples." (<bib id="Manning/Schütze2003:25">
<person name="Manning, Christopher D.">Manning</person>/<person name="Schütze, Hinrich">Schütze</person>Manning/Schütze 2003: 25</bib>).</p>
<p type="details">Zipfs Gesetz vermittelt also ganz allgemein die Erkenntnis: "[...] [W]hat makes frequency-based approaches to language hard is that almost all words are rare." (<bib id="Manning/Schütze2003:29">
<person name="Manning, Christopher D.">Manning</person>/<person name="Schütze, Hinrich">Schütze</person>Manning/Schütze 2003: 29</bib>).</p>
</page>
<page>
<p>Referenzliteratur:</p>
<ul>
<li>vgl. Bubenhofer 2009: 137-139</li>
<li>vgl. Evert 2009: 1224-1228, 1235</li>
<li>vgl. Heyer/Quasthoff/Wittig 2008: 87-89</li>
<li>vgl. Lemnitzer/Zinsmeister 2010: 148</li>
<li>vgl. Manning/Schütze 2003: 23-29, 171, 174</li>
<li>vgl. Perkuhn/Keibel/Kupietz 2012: 100-102, 114, 118f</li>
<li>Onlinequelle: Bubenhofer, Noah (2006-2011)</li>
</ul> 
<p>Davon lohnenswerte/lesenswerte Vertiefungsliteratur:</p>
<ul>
<li>vgl. Evert 2009: 1224-1239</li>
<li>Manning/Schütze 2003: 23-29; 168-182</li>
<li>Perkuhn/Keibel/Kupietz 2012: 100-102; 113-116</li>
</ul>
</page>
</chapter>
<chapter id="6">
<page>
<h1>Mögliche Gründe für die Kohäsion von Wörtern</h1>
<p>Kommen zwei Wörter immer wieder gemeinsam vor, so liegt es nahe, dass ein funktionaler oder inhaltlicher Zusammenhang zwischen ihnen besteht. Eine starke Anziehungskraft zwischen Bezugswort und Kollokator 
kann verschiedene Ursachen haben, ist aber zumeist einer paradigmatischen oder statistisch-syntagmatischen Relation geschuldet. </p>
<p>Mögliche Gründe für einen erhöhten Kohäsionsgrad sind:</p>
<ul>
<li>a)	Dependenzen (z.B. "Sonne scheint" oder "Hund bellt")</li>
<li>b)	Es handelt sich um Eigennamen.</li>
<li>c)	Der Kollokator ist ein Ober- oder Unterbegriff des Bezugswortes.</li>
<li>d)	Der Kollokator ist ein Synonym oder Antonym des Bezugswortes.</li>
<li>e)	Kollokator und Bezugswort sind Teil einer Aufzählung.</li>
<li>f)	Die Kollokation ist Teil von oder bildet ein Idiom oder eine Phrase.</li>
<li>g)	Kollokator und Bezugswort stehen in kausaler Beziehung (z.B. "Feuer" und "Kurzschluss").</li>
<li>h)	Der Kollokator oder das Bezugswort dient als Hilfsmittel oder Werkzeug (z.B. "Lupe" zu "Vergrößerung").</li>
<li>i)	Es liegt eine Teil-Ganzes-Beziehung vor (z.B. "Seiten" und "Buch").</li>
<li>j)	Der Kollokator oder das Bezugswort drückt einen Handlungsträger oder Objekte einer Handlung aus (z.B. "Amokläufer" und "tötet" oder "Bier" und "trinken").</li>
<li>k)	Der Kollokator oder das Bezugswort benennt typische Eigenschaften (z.B. "verschlossen" bei "Tür").</li>
<li>l)	Der Kollokator oder das Bezugswort ist eine Maßangabe zu einem Stoff (z.B. "Tonne" zu "Getreide").</li>
</ul>
<p>Zudem können Kollokationen semantische Kompatibilität, kulturelle Stereotypen oder institutionalisierte Phrasen reflektieren oder einfach als Beschreibung einer realen Situation dienen.</p>
<p>Die aufgeführten Gründe können zugleich als Interpretationsgrundlage/-hilfe dienen.</p>
</page>
<page>
<p>Referenzliteratur:</p>
<ul>
<li>vgl. Evert 2009: 1218f.</li>
<li>vgl. Heyer/Quasthoff/Wittig 2008: 24-38, 148f.</li>
</ul>
</page>
</chapter>
<chapter id="7">
<page>
<h1>Parameter</h1>
<p>Die einer Kollokationsanalyse zugrundeliegenden Parameter können je nach Fragestellung bzw. Hypothese variiert werden und bieten zugleich die Möglichkeit verschiedene Sichtweisen auf den Untersuchungsgegenstand einzunehmen. 
Man sollte sich stets bewusst sein, dass die Wahl der Parameter auch den Fokus des Forschers lenkt und maßgeblich die Ergebnisse der Analyse beeinflusst.</p>
<p type="details"><person name="Evert, Stefan">Evert</person> fasst dies wie folgt zusammen: "The resulting set or ranking of collocations depends on many parameters, including the size and composition of the corpus, 
[...], application of frequency thresholds, the definition of cooccurrence used, and the choice of association measure. It is up to the researcher to find a suitable and meaningful combination of parameters, 
or to draw on results from multiple parameter settings in order to highlight different aspects of collocativity. (<bib id="Evert2009:1243"><person name="Evert, Stefan">Evert</person>2009: 1243</bib>)</p>
<p>Es ist eine gewisse Herausforderung, dass bei der Entscheidung für die jeweiligen Parameter Annahmen über die Natur des Phänomens vorweggenommen werden müssen. </p>
<p>Bei einem datengeleiteten Vorgehen lässt man sich daher, wie der Name andeutet, in einem gewissen Maß von den Ergebnissen leiten und justiert die Parameter wenn nötig nach.</p>
<p>Darüber hinaus kann die Kollokationsanalyse dazu anregen, Fragestellungen bzw. Hypothesen zu formulieren oder zu beantworten, die möglicherweise erst durch die Analyse erkennbar werden.</p>
</page>
<page>
<p>Zu den regulierbaren Parametern einer Kollokationsanalyse gehören:</p>
</page>
<page>
<h2>Die Fenstergröße</h2>
<p>Kollokationen müssen nicht zwangsläufig aus zwei Wörtern bestehen, die unmittelbar aufeinander folgen, sondern können auch diskontinuierlich sein. Bei einer Kollokationsanalyse definiert man daher üblicherweise im Vorfeld 
den Ko- bzw. Kontext, der einbezogen werden soll. "Häufig wird eine Spanne von jeweils fünf Wörtern zur Linken und zur Rechten als der aussagekräftigste Kontext betrachtet [...]." 
(<bib id="Perkuhn/Keibel/Kupietz2012:111"><person name="Perkuhn, Rainer">Perkuhn</person>/<person name="Keibel, Holger">Keibel</person>/<person name="Kupietz, Marc">Kupietz </person>2012: 111</bib>) 
Auch hier ist wieder die Fragestellung ausschlaggebend, denn asymmetrische oder sehr eng gefasste Textfenster können sich genauso für die Analyse anbieten.</p>
<p type="details">Untersucht man beispielsweise die Frage, welche Adjektive eine signifikante Verbindung mit einem bestimmten Substantiv eingehen, so liegt es aufgrund der Wortstellung im Deutschen nahe, 
ein linksseitiges Fenster zu wählen.</p>
<p>Die Analyseergebnisse werden folgendermaßen dargestellt: Erscheint ein Kollokator als linker Nachbar des Bezugswortes, so wird die Position mit einem "-" gekennzeichnet. 
-3 würde also bedeuten, dass der Kollokator (z.B. "heiß") die dritte Stelle vor dem Bezugswort (z.B. "Wasser") besetzt.</p>
<p type="example"> Beispiel: "Wirklich <emph>heiß</emph> war das <kursiv>Wasser</kursiv> selten."</p>
</page>
</chapter>
</module>
</course>
